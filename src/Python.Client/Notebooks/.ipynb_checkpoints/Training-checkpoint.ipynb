{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "!pip install nest_asyncio\n",
    "from logging.handlers import TimedRotatingFileHandler\n",
    "import logging.config\n",
    "from psenti import SentimentAnalysis, SentimentConnection, Document\n",
    "from sklearn import metrics\n",
    "import socket\n",
    "\n",
    "user_name = socket.gethostname()\n",
    "host = '127.0.0.1'\n",
    "port = 5000\n",
    "\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "nest_asyncio.apply(loop=asyncio.get_event_loop())\n",
    "\n",
    "logger = logging.getLogger('JupyterUI')\n",
    "logFormatter = logging.Formatter('%(asctime)s - [%(thread)s] [%(threadName)s]- %(name)s - %(levelname)s - %(message)s')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "console = logging.StreamHandler()\n",
    "console.setFormatter(logFormatter)\n",
    "console.setLevel(logging.INFO)\n",
    "\n",
    "logger.addHandler(console)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "connection = SentimentConnection(host=host, port=port, client_id=user_name)\n",
    "logger.info(f'Supported domains')\n",
    "for domain in connection.supported_domains:    \n",
    "    logger.info(f'Domain: [{domain}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Test routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def test_sentiment(test_doc, model=None):\n",
    "    logger.info(f'Using {len(test_doc)} test documents...')\n",
    "    \n",
    "    analysis = SentimentAnalysis(connection, model=model, clean=True)\n",
    "    \n",
    "    results = []\n",
    "    detected_document_class = {}\n",
    "    analysis.on_message.subscribe(lambda result: results.append(result))\n",
    "    analysis.detect_sentiment(test_doc)\n",
    "\n",
    "    for result in results:\n",
    "        stars = result['Stars']    \n",
    "        id  = result['Id']\n",
    "        detected_document_class[id] = stars is not None and stars > 3\n",
    "\n",
    "    logger.info(f'Total processed documents: {len(detected_document_class)}')\n",
    "\n",
    "    test_y = [document.IsPositive for document in test_doc]\n",
    "    result_y = [detected_document_class[document.Id] for document in test_doc]\n",
    "    vacc = metrics.accuracy_score(test_y, result_y)\n",
    "    logger.info(f'Accuracy: {vacc:1.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Amazon reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "id = 0 \n",
    "all_amazon_documents = []\n",
    "\n",
    "with open('../data/amazon/positive.txt', \"r\", encoding='utf8') as reader:\n",
    "    for line in reader:\n",
    "        doc = Document(line, id)\n",
    "        doc.IsPositive = True\n",
    "        all_amazon_documents.append(doc)        \n",
    "        id += 1\n",
    "    \n",
    "with open('../data/amazon/negative.txt', \"r\", encoding='utf8') as reader:\n",
    "    for line in reader:\n",
    "        doc = Document(line, id)    \n",
    "        doc.IsPositive = False\n",
    "        all_amazon_documents.append(doc)\n",
    "        id += 1\n",
    "    \n",
    "train_doc, test_doc = train_test_split(all_amazon_documents, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with default model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentiment(test_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Sentiment Analysis model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "connection.delete_documents('Amazon2')\n",
    "connection.save_documents('Amazon2', train_doc)\n",
    "analysis = SentimentAnalysis(connection, clean=True)\n",
    "analysis.train('Amazon2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "test_sentiment(test_doc, 'Amazon2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-tensor-gpu] *",
   "language": "python",
   "name": "conda-env-.conda-tensor-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
